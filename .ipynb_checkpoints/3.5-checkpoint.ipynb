{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from gensim.models import word2vec \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from gensim.models import word2vec \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import AdaBoostClassifier as ADA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from gensim.models import word2vec \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import AdaBoostClassifier as ADA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier# 多层感知机\n",
    "from sklearn.experimental import enable_hist_gradient_boosting#Histogram-Based Gradient Boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from gensim.models import word2vec \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 学习器最优组合的寻找"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    生成训练数据\n",
    "'''\n",
    "\n",
    "def str2list(x):\n",
    "    x=eval(x)\n",
    "    return x\n",
    "\n",
    "'''\n",
    "    生成训练数据\n",
    "'''\n",
    "train_file=pd.read_csv('train_s04.csv')\n",
    "X_train=np.array(list(train_file['feature_row'].apply(str2list)))\n",
    "y_train=np.array(list(train_file['Boole']))\n",
    "\n",
    "'''\n",
    "    生成测试数据\n",
    "'''\n",
    "test_file=pd.read_csv('test_s04.csv')\n",
    "X_test=np.array(list(test_file['feature_row'].apply(str2list)))\n",
    "y_test=np.array(list(test_file['Boole']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类器类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs=[RandomForestClassifier(n_estimators=145, random_state=0),\n",
    "      XGBClassifier(n_estimator=500,max_depth=13,min_child_weight=0.509353199,gamma=0.297658057,objective=\"binary:logistic\"),\n",
    "      ADA(n_estimators=980),\n",
    "      neighbors.KNeighborsClassifier(n_neighbors=50, weights='distance')\n",
    "     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 产生一级学习器的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器：RandomForestClassifier(n_estimators=145, random_state=0)\n",
      "本次运行时间:  [14.983800800000001]\n",
      "本次AUC  0.8521931296009406\n",
      "ACU组= [0.8521931296009406]\n",
      "分类器：XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=0.297658057,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=13,\n",
      "              min_child_weight=0.509353199, missing=nan,\n",
      "              monotone_constraints=None, n_estimator=500, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, scale_pos_weight=None,\n",
      "              subsample=None, tree_method=None, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "[01:05:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:05:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:05:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:05:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:05:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "本次运行时间:  [14.983800800000001, 5.0608196]\n",
      "本次AUC  0.8499272897171244\n",
      "ACU组= [0.8521931296009406, 0.8499272897171244]\n",
      "分类器：AdaBoostClassifier(n_estimators=980)\n",
      "本次运行时间:  [14.983800800000001, 5.0608196, 49.323305999999995]\n",
      "本次AUC  0.6977259162211225\n",
      "ACU组= [0.8521931296009406, 0.8499272897171244, 0.6977259162211225]\n",
      "分类器：KNeighborsClassifier(n_neighbors=50, weights='distance')\n",
      "本次运行时间:  [14.983800800000001, 5.0608196, 49.323305999999995, 0.2660496]\n",
      "本次AUC  0.8517403489862545\n",
      "ACU组= [0.8521931296009406, 0.8499272897171244, 0.6977259162211225, 0.8517403489862545]\n"
     ]
    }
   ],
   "source": [
    "# 图（1）箭头所指。训练结果组成的特征矩阵， n训练样本 行 * n分类算法 列，即X_train.shape[0]* len(clfs)，这里是3000*4\n",
    "X_train_stack  = np.zeros((X_train.shape[0], len(clfs)))\n",
    "#图（2）箭头所指。3000*4\n",
    "X_test_stack = np.zeros((X_test.shape[0], len(clfs))) \n",
    "\n",
    "### 5折stacking\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1)#\n",
    "aucs=[]\n",
    "run_time=[]\n",
    "ii=[]\n",
    "meta_x=X_train_stack\n",
    "meta_y=X_test_stack\n",
    "meta_label=y_test\n",
    "for i,clf in enumerate(clfs):\n",
    "    print(\"分类器：{}\".format(clf))\n",
    "    tem_auc=0\n",
    "\n",
    "    X_stack_test_n = np.zeros((X_test.shape[0], n_folds))\n",
    "    tem_ii=0.0\n",
    "    for j,(train_index,test_index) in enumerate(skf.split(X_train,y_train)):\n",
    "        tr_x = X_train[train_index]\n",
    "        tr_y = y_train[train_index]\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "        clf.fit(tr_x, tr_y)\n",
    "        end = datetime.datetime.now()\n",
    "        tem_ii+=(end-start).total_seconds()\n",
    "        \n",
    "        #每得到一个模型就可以进行一次对测试集的预测\n",
    "        pred = clf.predict_proba(X_test)[:,1]\n",
    "        tem_auc+=roc_auc_score(y_test,pred)\n",
    "#         show_auc(model,test_data,test_label,title_name)\n",
    "\n",
    "        #生成stacking训练数据集\n",
    "        X_train_stack [test_index, i] = clf.predict_proba(X_train[test_index])[:,1]#对验证集的预测\n",
    "        X_stack_test_n[:,j] = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    ii.append(tem_ii/5)\n",
    "    print('本次运行时间: ',ii)\n",
    "    aucs.append(tem_auc/5)\n",
    "    print('本次AUC ',tem_auc/5)\n",
    "\n",
    "    #生成stacking测试数据集\n",
    "    X_test_stack[:,i] = X_stack_test_n.mean(axis=1) \n",
    "    print('ACU组=',aucs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8521931296009406\n",
      "0.8499272897171244\n",
      "0.6977259162211225\n",
      "0.8517403489862545\n"
     ]
    }
   ],
   "source": [
    "s=0.8521931296009406, 0.8499272897171244, 0.6977259162211225, 0.8517403489862545\n",
    "for i in s:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始查询所有组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3\n",
      "0 1 2\n",
      "0 1 3\n",
      "0 1\n",
      "0 2 3\n",
      "0 2\n",
      "0 3\n",
      "1 2 3\n",
      "1 2\n",
      "1 3\n",
      "2 3\n",
      "{'4123': 0.8537871508332937, '412': 0.8539102835535366, '413': 0.8537871093302141, '41': 0.8539102005473772, '423': 0.8539377516751074, '42': 0.8540197548433834, '43': 0.8539377032548479, '123': 0.8537288044204376, '12': 0.8522219036860856, '13': 0.8537288044204376, '23': 0.8538945400519764}\n"
     ]
    }
   ],
   "source": [
    "def meta_learn(x_stack,y_stack):\n",
    "    clf_second =LogisticRegression(solver=\"lbfgs\")\n",
    "    clf_second.fit(x_stack,y_train)\n",
    "    pred = clf_second.predict_proba(y_stack)[:,1]\n",
    "    tem_auc=roc_auc_score(y_test,pred)#得出预测结果\n",
    "    return tem_auc\n",
    "\n",
    "t=[0.1,0.2,0.3,0.4]\n",
    "aucs=[]#记录各组的成绩\n",
    "id={}\n",
    "for i in range(len(t)):\n",
    "    # 第一层\n",
    "    for j in range(i+1,len(t)):\n",
    "        \n",
    "        for k in range(j+1,len(t)):\n",
    "            \n",
    "            for ii in range(k+1,len(t)):\n",
    "                #创建数据部分\n",
    "                f=4\n",
    "                x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "                y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "                tem_id=''\n",
    "                for t1,t2 in enumerate([i,j,k,ii]):#更换矩阵对应的列即做到保存输出\n",
    "                    x_stack[:,t1]= X_train_stack[:,t2]\n",
    "                    y_stack[:,t1]=X_test_stack[:,t2]\n",
    "                    if(str(t2))=='0':\n",
    "                        t2='4'\n",
    "                    tem_id+=str(t2)\n",
    "                #元学习器学习部分\n",
    "                tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "                aucs.append(tem_auc)\n",
    "                id[tem_id]=tem_auc\n",
    "                print(i,j,k,ii)\n",
    "                  \n",
    "            f=3\n",
    "            x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "            y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "            tem_id=''\n",
    "            for t1,t2 in enumerate([i,j,k]):#更换矩阵对应的列即做到保存输出\n",
    "                x_stack[:,t1]= X_train_stack[:,t2]\n",
    "                y_stack[:,t1]=X_test_stack[:,t2]\n",
    "                if(str(t2))=='0':\n",
    "                    t2=4\n",
    "                tem_id+=str(t2)\n",
    "            #元学习器学习部分\n",
    "            tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "            aucs.append(tem_auc)\n",
    "            id[tem_id]=tem_auc\n",
    "            print(i,j,k)\n",
    "         \n",
    "        f=2\n",
    "        x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "        y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "        tem_id=''\n",
    "        for t1,t2 in enumerate([i,j]):#更换矩阵对应的列即做到保存输出\n",
    "            x_stack[:,t1]= X_train_stack[:,t2]\n",
    "            y_stack[:,t1]=X_test_stack[:,t2]\n",
    "            if(str(t2))=='0':\n",
    "                t2='4'\n",
    "            tem_id+=str(t2)\n",
    "        #元学习器学习部分\n",
    "        tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "        aucs.append(tem_auc)\n",
    "        id[tem_id]=tem_auc \n",
    "        print(i,j)\n",
    "\n",
    "print(id) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8537871508332937\n",
      "0.8539102835535366\n",
      "0.8537871093302141\n",
      "0.8539102005473772\n",
      "0.8539377516751074\n",
      "0.8540197548433834\n",
      "0.8539377032548479\n",
      "0.8537288044204376\n",
      "0.8522219036860856\n",
      "0.8537288044204376\n",
      "0.8538945400519764\n"
     ]
    }
   ],
   "source": [
    "for i in id:\n",
    "    print(id[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不同性能的个体学习器对集成效果的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 先是欠拟合组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs=[ \n",
    "#       ADA(n_estimators=50),\n",
    "#       XGBClassifier(n_estimators=28),\n",
    "#       neighbors.KNeighborsClassifier(n_neighbors=5,weights='distance'),\n",
    "      RandomForestClassifier(n_estimators=2),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器：RandomForestClassifier(n_estimators=2)\n",
      "本次运行时间:  [0.23402820000000002]\n",
      "本次AUC  0.8465503051738743\n",
      "ACU组= [0.8465503051738743]\n"
     ]
    }
   ],
   "source": [
    "# 图（1）箭头所指。训练结果组成的特征矩阵， n训练样本 行 * n分类算法 列，即X_train.shape[0]* len(clfs)，这里是3000*4\n",
    "X_train_stack  = np.zeros((X_train.shape[0], len(clfs)))\n",
    "#图（2）箭头所指。3000*4\n",
    "X_test_stack = np.zeros((X_test.shape[0], len(clfs))) \n",
    "\n",
    "### 5折stacking\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1)#\n",
    "aucs=[]\n",
    "run_time=[]\n",
    "ii=[]\n",
    "meta_x=X_train_stack\n",
    "meta_y=X_test_stack\n",
    "meta_label=y_test\n",
    "for i,clf in enumerate(clfs):\n",
    "    print(\"分类器：{}\".format(clf))\n",
    "    tem_auc=0\n",
    "\n",
    "    X_stack_test_n = np.zeros((X_test.shape[0], n_folds))\n",
    "    tem_ii=0.0\n",
    "    for j,(train_index,test_index) in enumerate(skf.split(X_train,y_train)):\n",
    "        tr_x = X_train[train_index]\n",
    "        tr_y = y_train[train_index]\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "        clf.fit(tr_x, tr_y)\n",
    "        end = datetime.datetime.now()\n",
    "        tem_ii+=(end-start).total_seconds()\n",
    "        \n",
    "        #每得到一个模型就可以进行一次对测试集的预测\n",
    "        pred = clf.predict_proba(X_test)[:,1]\n",
    "        tem_auc+=roc_auc_score(y_test,pred)\n",
    "#         show_auc(model,test_data,test_label,title_name)\n",
    "\n",
    "        #生成stacking训练数据集\n",
    "        X_train_stack [test_index, i] = clf.predict_proba(X_train[test_index])[:,1]#对验证集的预测\n",
    "        X_stack_test_n[:,j] = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    ii.append(tem_ii/5)\n",
    "    print('本次运行时间: ',ii)\n",
    "    aucs.append(tem_auc/5)\n",
    "    print('本次AUC ',tem_auc/5)\n",
    "\n",
    "    #生成stacking测试数据集\n",
    "    X_test_stack[:,i] = X_stack_test_n.mean(axis=1) \n",
    "    print('ACU组=',aucs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6456136152513027\n",
      "0.7574092297384646\n",
      "0.8053295411969426\n",
      "0.8466194057263945\n"
     ]
    }
   ],
   "source": [
    "s=0.6456136152513027, 0.7574092297384646, 0.8053295411969426, 0.8466194057263945\n",
    "for i in s:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8529672713284931"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_second =LogisticRegression(solver=\"lbfgs\")\n",
    "clf_second.fit(X_train_stack,y_train)\n",
    "pred = clf_second.predict_proba(X_test_stack)[:,1]\n",
    "tem=roc_auc_score(y_test,pred)#0.9946\n",
    "tem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3\n",
      "0 1 2\n",
      "0 1 3\n",
      "0 1\n",
      "0 2 3\n",
      "0 2\n",
      "0 3\n",
      "1 2 3\n",
      "1 2\n",
      "1 3\n",
      "2 3\n",
      "{'4123': 0.8530128762958861, '412': 0.839792519879197, '413': 0.8528845418563227, '41': 0.7689036895788224, '423': 0.8530288895674643, '42': 0.8436609458475771, '43': 0.8529060957890388, '123': 0.8530117142096549, '12': 0.8396964264153683, '13': 0.8528848946325001, '23': 0.853032458832317}\n"
     ]
    }
   ],
   "source": [
    "def meta_learn(x_stack,y_stack):\n",
    "    clf_second =LogisticRegression(solver=\"lbfgs\")\n",
    "    clf_second.fit(x_stack,y_train)\n",
    "    pred = clf_second.predict_proba(y_stack)[:,1]\n",
    "    tem_auc=roc_auc_score(y_test,pred)#得出预测结果\n",
    "    return tem_auc\n",
    "\n",
    "t=[0.1,0.2,0.3,0.4]\n",
    "aucs=[]#记录各组的成绩\n",
    "id0={}\n",
    "for i in range(len(t)):\n",
    "    # 第一层\n",
    "    for j in range(i+1,len(t)):\n",
    "        \n",
    "        for k in range(j+1,len(t)):\n",
    "            \n",
    "            for ii in range(k+1,len(t)):\n",
    "                #创建数据部分\n",
    "                f=4\n",
    "                x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "                y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "                tem_id=''\n",
    "                for t1,t2 in enumerate([i,j,k,ii]):#更换矩阵对应的列即做到保存输出\n",
    "                    x_stack[:,t1]= X_train_stack[:,t2]\n",
    "                    y_stack[:,t1]=X_test_stack[:,t2]\n",
    "                    if(str(t2))=='0':\n",
    "                        t2='4'\n",
    "                    tem_id+=str(t2)\n",
    "                #元学习器学习部分\n",
    "                tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "                aucs.append(tem_auc)\n",
    "                id0[tem_id]=tem_auc\n",
    "                print(i,j,k,ii)\n",
    "                  \n",
    "            f=3\n",
    "            x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "            y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "            tem_id=''\n",
    "            for t1,t2 in enumerate([i,j,k]):#更换矩阵对应的列即做到保存输出\n",
    "                x_stack[:,t1]= X_train_stack[:,t2]\n",
    "                y_stack[:,t1]=X_test_stack[:,t2]\n",
    "                if(str(t2))=='0':\n",
    "                    t2=4\n",
    "                tem_id+=str(t2)\n",
    "            #元学习器学习部分\n",
    "            tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "            aucs.append(tem_auc)\n",
    "            id0[tem_id]=tem_auc\n",
    "            print(i,j,k)\n",
    "         \n",
    "        f=2\n",
    "        x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "        y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "        tem_id=''\n",
    "        for t1,t2 in enumerate([i,j]):#更换矩阵对应的列即做到保存输出\n",
    "            x_stack[:,t1]= X_train_stack[:,t2]\n",
    "            y_stack[:,t1]=X_test_stack[:,t2]\n",
    "            if(str(t2))=='0':\n",
    "                t2='4'\n",
    "            tem_id+=str(t2)\n",
    "        #元学习器学习部分\n",
    "        tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "        aucs.append(tem_auc)\n",
    "        id0[tem_id]=tem_auc \n",
    "        print(i,j)\n",
    "\n",
    "print(id0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8530128762958861\n",
      "0.839792519879197\n",
      "0.8528845418563227\n",
      "0.7689036895788224\n",
      "0.8530288895674643\n",
      "0.8436609458475771\n",
      "0.8529060957890388\n",
      "0.8530117142096549\n",
      "0.8396964264153683\n",
      "0.8528848946325001\n",
      "0.853032458832317\n"
     ]
    }
   ],
   "source": [
    "for i in id0:\n",
    "    print(id0[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 然后是极大组\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs=[\n",
    "      ADA(n_estimators=2000),\n",
    "      XGBClassifier(n_estimators=1000,max_depth=15,min_child_weight=0.25,gamma=0.297658057,objective=\"binary:logistic\"),\n",
    "      neighbors.KNeighborsClassifier( n_neighbors=3000,weights='distance'),\n",
    "      RandomForestClassifier( n_estimators=500,random_state=0),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器：AdaBoostClassifier(n_estimators=2000)\n",
      "本次运行时间:  [102.1923522]\n",
      "本次AUC  0.7159360481812019\n",
      "ACU组= [0.7159360481812019]\n",
      "分类器：XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=0.297658057,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=15,\n",
      "              min_child_weight=0.25, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "[16:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:30:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:31:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:32:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "本次运行时间:  [102.1923522, 54.93053719999999]\n",
      "本次AUC  0.8512599141778567\n",
      "ACU组= [0.7159360481812019, 0.8512599141778567]\n",
      "分类器：KNeighborsClassifier(n_neighbors=3000, weights='distance')\n",
      "本次运行时间:  [102.1923522, 54.93053719999999, 0.22061920000000002]\n",
      "本次AUC  0.8524937149638351\n",
      "ACU组= [0.7159360481812019, 0.8512599141778567, 0.8524937149638351]\n",
      "分类器：RandomForestClassifier(n_estimators=500, random_state=0)\n",
      "本次运行时间:  [102.1923522, 54.93053719999999, 0.22061920000000002, 64.6370556]\n",
      "本次AUC  0.8522464755844126\n",
      "ACU组= [0.7159360481812019, 0.8512599141778567, 0.8524937149638351, 0.8522464755844126]\n"
     ]
    }
   ],
   "source": [
    "# 图（1）箭头所指。训练结果组成的特征矩阵， n训练样本 行 * n分类算法 列，即X_train.shape[0]* len(clfs)，这里是3000*4\n",
    "X_train_stack  = np.zeros((X_train.shape[0], len(clfs)))\n",
    "#图（2）箭头所指。3000*4\n",
    "X_test_stack = np.zeros((X_test.shape[0], len(clfs))) \n",
    "\n",
    "### 5折stacking\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1)#\n",
    "aucs=[]\n",
    "run_time=[]\n",
    "ii=[]\n",
    "meta_x=X_train_stack\n",
    "meta_y=X_test_stack\n",
    "meta_label=y_test\n",
    "for i,clf in enumerate(clfs):\n",
    "    print(\"分类器：{}\".format(clf))\n",
    "    tem_auc=0\n",
    "\n",
    "    X_stack_test_n = np.zeros((X_test.shape[0], n_folds))\n",
    "    tem_ii=0.0\n",
    "    for j,(train_index,test_index) in enumerate(skf.split(X_train,y_train)):\n",
    "        tr_x = X_train[train_index]\n",
    "        tr_y = y_train[train_index]\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "        clf.fit(tr_x, tr_y)\n",
    "        end = datetime.datetime.now()\n",
    "        tem_ii+=(end-start).total_seconds()\n",
    "        \n",
    "        #每得到一个模型就可以进行一次对测试集的预测\n",
    "        pred = clf.predict_proba(X_test)[:,1]\n",
    "        tem_auc+=roc_auc_score(y_test,pred)\n",
    "#         show_auc(model,test_data,test_label,title_name)\n",
    "\n",
    "        #生成stacking训练数据集\n",
    "        X_train_stack [test_index, i] = clf.predict_proba(X_train[test_index])[:,1]#对验证集的预测\n",
    "        X_stack_test_n[:,j] = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    ii.append(tem_ii/5)\n",
    "    print('本次运行时间: ',ii)\n",
    "    aucs.append(tem_auc/5)\n",
    "    print('本次AUC ',tem_auc/5)\n",
    "\n",
    "    #生成stacking测试数据集\n",
    "    X_test_stack[:,i] = X_stack_test_n.mean(axis=1) \n",
    "    print('ACU组=',aucs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7159360481812019\n",
      "0.8512599141778567\n",
      "0.8524937149638351\n",
      "0.8522464755844126\n"
     ]
    }
   ],
   "source": [
    "s=0.7159360481812019, 0.8512599141778567, 0.8524937149638351, 0.8522464755844126\n",
    "for i in s:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3\n",
      "0 1 2\n",
      "0 1 3\n",
      "0 1\n",
      "0 2 3\n",
      "0 2\n",
      "0 3\n",
      "1 2 3\n",
      "1 2\n",
      "1 3\n",
      "2 3\n",
      "{'4123': 0.8539670182634649, '412': 0.8539648739376811, '413': 0.8540126716511174, '41': 0.8532368545825815, '423': 0.8540473613085534, '42': 0.8540507092236479, '43': 0.854021650150689, '123': 0.8539670459321845, '12': 0.8539648739376811, '13': 0.8540126716511174, '23': 0.8540473613085535}\n"
     ]
    }
   ],
   "source": [
    "def meta_learn(x_stack,y_stack):\n",
    "    clf_second =LogisticRegression(solver=\"lbfgs\")\n",
    "    clf_second.fit(x_stack,y_train)\n",
    "    pred = clf_second.predict_proba(y_stack)[:,1]\n",
    "    tem_auc=roc_auc_score(y_test,pred)#得出预测结果\n",
    "    return tem_auc\n",
    "\n",
    "t=[0.1,0.2,0.3,0.4]\n",
    "aucs=[]#记录各组的成绩\n",
    "id2={}\n",
    "for i in range(len(t)):\n",
    "    # 第一层\n",
    "    for j in range(i+1,len(t)):\n",
    "        \n",
    "        for k in range(j+1,len(t)):\n",
    "            \n",
    "            for ii in range(k+1,len(t)):\n",
    "                #创建数据部分\n",
    "                f=4\n",
    "                x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "                y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "                tem_id=''\n",
    "                for t1,t2 in enumerate([i,j,k,ii]):#更换矩阵对应的列即做到保存输出\n",
    "                    x_stack[:,t1]= X_train_stack[:,t2]\n",
    "                    y_stack[:,t1]=X_test_stack[:,t2]\n",
    "                    if(str(t2))=='0':\n",
    "                        t2='4'\n",
    "                    tem_id+=str(t2)\n",
    "                #元学习器学习部分\n",
    "                tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "                aucs.append(tem_auc)\n",
    "                id2[tem_id]=tem_auc\n",
    "                print(i,j,k,ii)\n",
    "                  \n",
    "            f=3\n",
    "            x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "            y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "            tem_id=''\n",
    "            for t1,t2 in enumerate([i,j,k]):#更换矩阵对应的列即做到保存输出\n",
    "                x_stack[:,t1]= X_train_stack[:,t2]\n",
    "                y_stack[:,t1]=X_test_stack[:,t2]\n",
    "                if(str(t2))=='0':\n",
    "                    t2=4\n",
    "                tem_id+=str(t2)\n",
    "            #元学习器学习部分\n",
    "            tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "            aucs.append(tem_auc)\n",
    "            id2[tem_id]=tem_auc\n",
    "            print(i,j,k)\n",
    "         \n",
    "        f=2\n",
    "        x_stack=np.zeros((X_train.shape[0], f))#创建空矩阵，用于存储第一层的训练输出\n",
    "        y_stack=np.zeros((X_test.shape[0], f))#创建空矩阵，用于存储第一层的测试输出\n",
    "        tem_id=''\n",
    "        for t1,t2 in enumerate([i,j]):#更换矩阵对应的列即做到保存输出\n",
    "            x_stack[:,t1]= X_train_stack[:,t2]\n",
    "            y_stack[:,t1]=X_test_stack[:,t2]\n",
    "            if(str(t2))=='0':\n",
    "                t2='4'\n",
    "            tem_id+=str(t2)\n",
    "        #元学习器学习部分\n",
    "        tem_auc=meta_learn(x_stack,y_stack)#得出预测结果\n",
    "        aucs.append(tem_auc)\n",
    "        id2[tem_id]=tem_auc \n",
    "        print(i,j)\n",
    "\n",
    "print(id2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8539670182634649\n",
      "0.8539648739376811\n",
      "0.8540126716511174\n",
      "0.8532368545825815\n",
      "0.8540473613085534\n",
      "0.8540507092236479\n",
      "0.854021650150689\n",
      "0.8539670459321845\n",
      "0.8539648739376811\n",
      "0.8540126716511174\n",
      "0.8540473613085535\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in id2 :\n",
    "    print(id2[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
