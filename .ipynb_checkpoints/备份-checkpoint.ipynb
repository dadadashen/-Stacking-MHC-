{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ①删除宿主为mouse的数据文件。\n",
    "    ②将每个文件的的制表符通通改成逗号。将每个文件的后缀从'.txt'更改为‘.csv'\n",
    "    ③删除每个文件不必要的列。\n",
    "    ④将train和test类的文件分别移动到两个文件夹中----文件夹train和文件夹test\n",
    "    ⑤因为数据集采用的是5折交叉验证，所以需要将文件夹train和文件夹test的文件分为5份，并分到不同的文件夹中\n",
    "    ⑥数据来源：http://tools.iedb.org/mhcii/download/ 中的“MHC-II binding dataset ”中的“class_II_similarity_reduced_5cv_sep”\n",
    "    ⑦ps：以下代码只能执行一次，因为执行一次后文件名、文件路径会变，第二次执行会因为找不到而出错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def modify_test(file_name):\n",
    "#该函数能够将 文本的的制表符通通改成逗号\n",
    "    #先复制，再清空原本的，最后将修改过的复制内容写入\n",
    "    with open(file_name, \"r+\") as file_object:\n",
    "        read_data=file_object.read()# 用一个临时变量 read_data 存储文本内容\n",
    "        file_object.seek(0)#把文件定位到position 0，没有这句的话，文件是定位到数据最后，truncate也是从这里删除，所以感觉就是没起作用。\n",
    "        file_object.truncate()   #清空文件\n",
    "        file_object.write(read_data.replace('\\t', ','))\n",
    "\n",
    "        \n",
    "dateset_path='class_II_similarity_reduced_5cv_sep'#数据集的路径\n",
    "dirs = os.listdir(dateset_path)# os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。\n",
    "\n",
    "for file in dirs:    \n",
    "    '''\n",
    "        ①删除宿主为mouse的数据。\n",
    "    '''\n",
    "    if 'H-2-' in file:\n",
    "        os.remove(dateset_path+'\\\\'+file)\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    '''\n",
    "        ②将文本的的制表符通通改成逗号，目的是为了生成合格的csv文件。将每个文件的后缀从'.txt'更改为‘.csv'\n",
    "    '''\n",
    "    modify_test(dateset_path+'\\\\'+file)\n",
    "    portion = os.path.splitext(dateset_path+'\\\\'+file)  # 分离文件名与扩展名\n",
    "    # 如果后缀是‘.txt'\n",
    "    if portion[1] == '.txt':\n",
    "       # 重新组合文件名和后缀名\n",
    "        newname = portion[0] + '.csv'\n",
    "        os.rename(dateset_path+'\\\\'+file, newname)\n",
    "        \n",
    "        \n",
    "'''\n",
    "    ③删除不必要的列\n",
    "'''\n",
    "dirs = os.listdir(dateset_path)#后缀都改了，所以文件名列表都要更新\n",
    "for file in dirs:\n",
    "    # 加载数据集,添加头一行的信息。\n",
    "    dataframe = pd.read_csv(dateset_path+'\\\\'+file,header=0,names=('host','allele','len','antigen','description','operator','value'))\n",
    "    # 删除不必要的属性，不会修改源文件\n",
    "    dataframe =dataframe.drop(['host','allele','len','antigen','operator'], axis=1)\n",
    "    true_value=[]#真实值，非 1 即 -1\n",
    "    threshold=1500#假设阈值为1500\n",
    "    for i in dataframe['value']:#根据亲和力大小来判断结合力的强弱。强为1，弱为0\n",
    "        if(i>=threshold):\n",
    "            true_value.append(1)\n",
    "        else:\n",
    "            true_value.append(-1)\n",
    "    dataframe.insert(1,\"Boole\",true_value)\n",
    "    dataframe.to_csv(dateset_path+'\\\\'+file)\n",
    "    \n",
    "    \n",
    "'''\n",
    "    ④将train和test类的文件分别移动到两个文件夹中\n",
    "'''\n",
    "dateset_path='class_II_similarity_reduced_5cv_sep'#数据集的路径\n",
    "to_train_path = dateset_path +'\\\\'+ 'train'\n",
    "to_test_path = dateset_path +'\\\\' + 'test'\n",
    "#  如果不存在train或test文件夹，则创建\n",
    "if not os.path.isdir(to_train_path):\n",
    "     os.makedirs(to_train_path)\n",
    "if not os.path.isdir(to_test_path):\n",
    "     os.makedirs(to_test_path)\n",
    "\n",
    "for file in dirs:\n",
    "     from_path = dateset_path+'\\\\'+file\n",
    "     if '_train_' in file:# 这样的缩进才是正确的，有毒\n",
    "         shutil.move(from_path, to_train_path)\n",
    "     else:\n",
    "         shutil.move(from_path, to_test_path)\n",
    "\n",
    "'''\n",
    "    ⑤因为数据集采用的是5折交叉验证，所以需要将文件夹train和文件夹test的文件分为5份，并分到不同的文件夹中\n",
    "'''\n",
    "\n",
    "train_dateset_path='class_II_similarity_reduced_5cv_sep'+'\\\\'+'train'\n",
    "train_dirs = os.listdir(train_dateset_path)\n",
    "\n",
    "#文件夹名\n",
    "to_train0_path = train_dateset_path +'\\\\'+ 'train0'\n",
    "to_train1_path = train_dateset_path +'\\\\'+ 'train1'\n",
    "to_train2_path = train_dateset_path +'\\\\'+ 'train2'\n",
    "to_train3_path = train_dateset_path +'\\\\'+ 'train3'\n",
    "to_train4_path = train_dateset_path +'\\\\'+ 'train4'\n",
    "\n",
    "#  如果不存在文件夹，则创建\n",
    "if not os.path.isdir(to_train0_path):\n",
    "     os.makedirs(to_train0_path)\n",
    "if not os.path.isdir(to_train1_path):\n",
    "     os.makedirs(to_train1_path)\n",
    "if not os.path.isdir(to_train2_path):\n",
    "     os.makedirs(to_train2_path)\n",
    "if not os.path.isdir(to_train3_path):\n",
    "     os.makedirs(to_train3_path)\n",
    "if not os.path.isdir(to_train4_path):\n",
    "     os.makedirs(to_train4_path)\n",
    "\n",
    "for file in train_dirs:\n",
    "    from_path = train_dateset_path+'\\\\'+file\n",
    "    if '_0.csv' in file:\n",
    "        shutil.move(from_path, to_train0_path)\n",
    "    elif '_1.csv' in file:\n",
    "        shutil.move(from_path, to_train1_path)\n",
    "    elif '_2.csv' in file:\n",
    "        shutil.move(from_path, to_train2_path)\n",
    "    elif '_3.csv' in file:\n",
    "        shutil.move(from_path, to_train3_path)\n",
    "    elif '_4.csv' in file:\n",
    "        shutil.move(from_path, to_train4_path)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "test_dateset_path='class_II_similarity_reduced_5cv_sep'+'\\\\'+'test'\n",
    "test_dirs = os.listdir(test_dateset_path)\n",
    "\n",
    "#文件夹名\n",
    "to_test0_path = test_dateset_path +'\\\\'+ 'test0'\n",
    "to_test1_path = test_dateset_path +'\\\\'+ 'test1'\n",
    "to_test2_path = test_dateset_path +'\\\\'+ 'test2'\n",
    "to_test3_path = test_dateset_path +'\\\\'+ 'test3'\n",
    "to_test4_path = test_dateset_path +'\\\\'+ 'test4'\n",
    "\n",
    "#  如果不存在文件夹，则创建\n",
    "if not os.path.isdir(to_test0_path):\n",
    "     os.makedirs(to_test0_path)\n",
    "if not os.path.isdir(to_test1_path):\n",
    "     os.makedirs(to_test1_path)\n",
    "if not os.path.isdir(to_test2_path):\n",
    "     os.makedirs(to_test2_path)\n",
    "if not os.path.isdir(to_test3_path):\n",
    "     os.makedirs(to_test3_path)\n",
    "if not os.path.isdir(to_test4_path):\n",
    "     os.makedirs(to_test4_path)\n",
    "\n",
    "for file in test_dirs:\n",
    "    from_path = test_dateset_path+'\\\\'+file\n",
    "    if '_0.csv' in file:\n",
    "        shutil.move(from_path, to_test0_path)\n",
    "    elif '_1.csv' in file:\n",
    "        shutil.move(from_path, to_test1_path)\n",
    "    elif '_2.csv' in file:\n",
    "        shutil.move(from_path, to_test2_path)\n",
    "    elif '_3.csv' in file:\n",
    "        shutil.move(from_path, to_test3_path)\n",
    "    elif '_4.csv' in file:\n",
    "        shutil.move(from_path, to_test4_path)\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
