{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prime-space",
   "metadata": {},
   "source": [
    "# 自动调参hyperopt\n",
    "##### 详细教程 1. https://www.cnblogs.com/gczr/p/7156270.html 2.https://cloud.tencent.com/developer/article/1471190 3.https://blog.csdn.net/qq_41076797/article/details/102941095\n",
    "##### github https://github.com/hyperopt/hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from random import shuffle\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp,space_eval,rand,Trials,partial,STATUS_OK\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "august-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from gensim.models import word2vec \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from gensim.models import word2vec \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import AdaBoostClassifier as ADA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from gensim.models import word2vec \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import AdaBoostClassifier as ADA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier# 多层感知机\n",
    "from sklearn.experimental import enable_hist_gradient_boosting#Histogram-Based Gradient Boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-rebound",
   "metadata": {},
   "source": [
    "## RF\n",
    "    before：max auc=  0.8514570479596963  mean auc=  0.8505288285987221 time=56.686443999999995"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-biography",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "    XGBClassifier(silent=0,gamma=0.22659969900596297, learning_rate=0.06, max_depth= 19,min_child_weight=0.7725754435821889,n_estimators=500)\n",
    "    before：max auc=  0.8155414142277833  mean auc=  0.8129296850714 time=13.921559\n",
    "    end：max auc=  0.849838234833785  mean auc=  0.8492620230670175 time=53.515729"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-bolivia",
   "metadata": {},
   "source": [
    "# 函数主体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from random import shuffle\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from hyperopt import fmin, tpe, hp,space_eval,rand,Trials,partial,STATUS_OK\n",
    "\n",
    "\n",
    "\n",
    "def GBM(argsDict):\n",
    "    C = argsDict[\"C\"]+0.05#[0.05,20.05]\n",
    "#     gamma = 1/argsDict['gamma']#[0.01,1]\n",
    "    print('C=', C)\n",
    "    print('gamma=',gamma)\n",
    "    \n",
    "    auc_cv=[]\n",
    "    start = datetime.datetime.now()\n",
    "    for i in range(5):\n",
    "        print('第',i+1,'次',end='')\n",
    "        train_5cv='train_data_5cv'+'//'+'t'+str(i)+'//'+'t'+str(i)+'.csv'# 路径为 /train_data_5cv/t0\n",
    "        test_5cv='train_data_5cv'+'//'+'t'+str(i)+'//'+'train'+str(i)+'.csv' #部分训练集用作验证集\n",
    "\n",
    "        #训练数据\n",
    "        train_file=pd.read_csv(train_5cv)\n",
    "        train_data=list(train_file['feature_row'].apply(str2list))\n",
    "        train_label=list(train_file['Boole'])\n",
    "        test_file=pd.read_csv(test_5cv)\n",
    "        test_data=list(test_file['feature_row'].apply(str2list))\n",
    "        test_label=list(test_file['Boole'])\n",
    "        \n",
    "        \n",
    "        model=svm.SVC(C=C,gamma='auto',kernel='rbf',decision_function_shape='ovo',probability=True) \n",
    "        model.fit(np.array(train_data),np.array(train_label))\n",
    "\n",
    "        pred = model.predict_proba(np.array(test_data))[:,1]\n",
    "        fpr, tpr, threshold = metrics.roc_curve(test_label, pred)\n",
    "        auc_cv.append(metrics.auc(fpr, tpr))\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    print('running time:',end=' ')\n",
    "    print((end-start).total_seconds())# 运行时间\n",
    "    s=0\n",
    "    for i in range(5):\n",
    "        s+=auc_cv[i]\n",
    "    print('auc= ',s/5)\n",
    "    return -s/5\n",
    "\n",
    "space = {\"C\":hp.randint(\"C\",20),\n",
    "#          \"gamma\":hp.randint(\"gamma\",100), #\n",
    "        }\n",
    "\n",
    "algo = partial(tpe.suggest,n_startup_jobs=1)\n",
    "best = fmin(GBM,space,algo=tpe.suggest,max_evals=20)#max_evals表示想要训练的最大模型数量，越大越容易找到最优解,algo = tpe.suggest\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precise-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(clfs):\n",
    "    \n",
    "    # 图（1）箭头所指。训练结果组成的特征矩阵， n训练样本 行 * n分类算法 列，即X_train.shape[0]* len(clfs)，这里是3000*4\n",
    "    X_train_stack  = np.zeros((X_train.shape[0], len(clfs)))\n",
    "    #图（2）箭头所指。3000*4\n",
    "    X_test_stack = np.zeros((X_test.shape[0], len(clfs))) \n",
    "\n",
    "    ### 5折stacking\n",
    "    n_folds = 5\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1)#\n",
    "    aucs=[]\n",
    "    run_time=[]\n",
    "    ii=[]\n",
    "    for i,clf in enumerate(clfs):\n",
    "        print(\"分类器：{}\".format(clf))\n",
    "        tem_auc=0\n",
    "        \n",
    "        X_stack_test_n = np.zeros((X_test.shape[0], n_folds))\n",
    "        tem_ii=0.0\n",
    "        for j,(train_index,test_index) in enumerate(skf.split(X_train,y_train)):\n",
    "            tr_x = X_train[train_index]\n",
    "            tr_y = y_train[train_index]\n",
    "            \n",
    "            start = datetime.datetime.now()\n",
    "            clf.fit(tr_x, tr_y)\n",
    "            end = datetime.datetime.now()\n",
    "            tem_ii+=(end-start).total_seconds()\n",
    "            #每得到一个模型就可以进行一次对测试集的预测\n",
    "            pred = clf.predict_proba(X_test)[:,1]\n",
    "            tem_auc+=roc_auc_score(y_test,pred)\n",
    "    #         show_auc(model,test_data,test_label,title_name)\n",
    "\n",
    "            #生成stacking训练数据集\n",
    "            X_train_stack [test_index, i] = clf.predict_proba(X_train[test_index])[:,1]#对验证集的预测\n",
    "            X_stack_test_n[:,j] = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "        ii.append(tem_ii/5)\n",
    "        print(ii)\n",
    "        aucs.append(tem_auc/5)\n",
    "        print(tem_auc/5)\n",
    "\n",
    "        #生成stacking测试数据集\n",
    "        X_test_stack[:,i] = X_stack_test_n.mean(axis=1) \n",
    "        print(aucs)\n",
    "\n",
    "    #按序输出各分类器的auc\n",
    "    return aucs,run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southeast-investor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[605, 615, 625, 635, 645, 655, 665, 675, 685, 695]\n",
      "[AdaBoostClassifier(n_estimators=605), AdaBoostClassifier(n_estimators=615), AdaBoostClassifier(n_estimators=625), AdaBoostClassifier(n_estimators=635), AdaBoostClassifier(n_estimators=645), AdaBoostClassifier(n_estimators=655), AdaBoostClassifier(n_estimators=665), AdaBoostClassifier(n_estimators=675), AdaBoostClassifier(n_estimators=685), AdaBoostClassifier(n_estimators=695)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9ca2c896bfb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mADA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_tree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-6fcd3d0739e5>\u001b[0m in \u001b[0;36mstack\u001b[1;34m(clfs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# 图（1）箭头所指。训练结果组成的特征矩阵， n训练样本 行 * n分类算法 列，即X_train.shape[0]* len(clfs)，这里是3000*4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_train_stack\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#图（2）箭头所指。3000*4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX_test_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "n_tree=[605]\n",
    "for i in range(1,10):\n",
    "    n_tree.append(n_tree[i-1]+10)\n",
    "clfs=[]\n",
    "print(n_tree)\n",
    "for i in range(len(n_tree)):\n",
    "    clfs.append(ADA(n_estimators=n_tree[i]))\n",
    "print(clfs)\n",
    "stack(clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-fiber",
   "metadata": {},
   "source": [
    "### 必要的包或函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stock-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(x):\n",
    "    x=eval(x)\n",
    "    return x\n",
    "def show_auc(model,test_data,test_label,title_name): #画出 ROC 曲线（receiver operating characteristic curve）\n",
    "    pred = model.predict_proba(np.array(test_data))[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(test_label, pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.title(title_name)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.3f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    print('AUC= ',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaging-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "#包多点，安全感也多点\n",
    "import os, sys\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from gensim.models import word2vec \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pylab as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import AdaBoostClassifier as ADA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier# 多层感知机\n",
    "from sklearn.experimental import enable_hist_gradient_boosting#Histogram-Based Gradient Boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-option",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
